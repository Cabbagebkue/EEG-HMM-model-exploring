{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77e54e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import itertools\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92c64896",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HMM:\n",
    "    def __init__(self,A,B,pi):\n",
    "        self.A = A \n",
    "        self.B = B\n",
    "        self.pi = pi\n",
    "   \n",
    "    #向前算法（F为/alpha_t(i)）\n",
    "    def _forward(self,obs_seq):\n",
    "        #取A = N x N\n",
    "        N = self.A.shape[0]\n",
    "        T = len(obs_seq)\n",
    "    \n",
    "        F = np.zeros((N,T))\n",
    "        \n",
    "        #alpha = pi*b\n",
    "        F[:,0] = self.pi * self.B[:,obs_seq[0]]\n",
    "        \n",
    "        for t in range(1,T):\n",
    "            for n in range(N):\n",
    "                #计算第t个时，第n个状态的前向概率\n",
    "                F[n,t] = np.dot(F[:,t-1],(self.A[:,n]))*self.B[n,obs_seq[t]]\n",
    "        return F\n",
    "\n",
    "    #向后算法\n",
    "    def _backward(self,obs_seq):\n",
    "        N = self.A.shape[0]\n",
    "        T = len(obs_seq)\n",
    "        \n",
    "        X = np.zeros((N,T))\n",
    "        #表示X矩阵的最后一列\n",
    "        X[:,-1:] = 1\n",
    "\n",
    "        for t in reversed(range(T-1)):\n",
    "            for n in range(N):\n",
    "                # 边权值为a_ji\n",
    "                X[n,t] = sum(X[:,t+1]*self.A[n,:]*self.B[:,obs_seq[t+1]])\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    #维特比算法\n",
    "    def viterbi(self,obs_seq):\n",
    "        \n",
    "        N = self.A.shape[0]\n",
    "        T = len(obs_seq)\n",
    "        \n",
    "        prev = np.zeros((T-1,N),dtype = int)\n",
    "        \n",
    "        V = np.zeros((N,T))\n",
    "        V[:,0]=self.pi*self.B[:,obs_seq[0]]\n",
    "        \n",
    "        for t in range(1,T):\n",
    "            for n in range(N):\n",
    "                #计算delta(j)*a_ji\n",
    "                seq_probs = V[:,t-1]*self.A[:,n]*self.B[n,obs_seq[t]]\n",
    "                #计算最大状态转移过程\n",
    "                prev[t-1,n] = np.argmax(seq_probs)\n",
    "                V[n,t] = max(seq_probs)\n",
    "                \n",
    "        return V,prev\n",
    "    \n",
    "    def build_viterbi_path(self,prev,last_state):\n",
    "        \"\"\"\n",
    "        returns a state path ending in last_state in reverse order\n",
    "        \"\"\"\n",
    "        T = len(prev)\n",
    "        yield(last_state)\n",
    "\n",
    "        #从T-1开始，每次下降1\n",
    "        for i in range(T-1,-1,-1):\n",
    "            yield(prev[i,last_state])\n",
    "            last_state = prev[i,last_state]\n",
    "\n",
    "    def stat_path(self,obs_seq):\n",
    "        V,prev = self.viterbi(obs_seq)\n",
    "        \n",
    "        #build state path with greatest probability\n",
    "        last_state = np.argmax(V[:,-1]) \n",
    "        path = list(self.build_viterbi_path(prev,last_state))\n",
    "        \n",
    "        return V[last_state,-1],reversed(path)\n",
    "    \n",
    "    #Baum-Welch算法\n",
    "    def baum_welch_train(self,observations,criterion=0.05):\n",
    "        n_states = self.A.shape[0]\n",
    "        #观察序列长度T\n",
    "        n_samples = len(observations)\n",
    "        \n",
    "        done = False\n",
    "        while not done:\n",
    "            #alpha_t(i) = P(o_1,o_2,...o_t,q_t = s_i | hmm)\n",
    "            #Initialize alpha\n",
    "            #获得所有向前传播节点值alpha_t(i)\n",
    "            alpha = self._forward(observations)\n",
    "            \n",
    "            \n",
    "            # beta_t(i) = P(o_t+1,o_t+2,...o_T | q_t = s_i, hmm)\n",
    "            # Initialize beta\n",
    "            # 获得所有后向传播节点值\n",
    "            beta = self._backward(observations)\n",
    "            \n",
    "            # compute xi_t(i,j) -> xi(i,j,t)\n",
    "            xi = np.zeros((n_states,n_states,n_samples-1))\n",
    "            # in each moment\n",
    "            for t in range(n_samples-1):\n",
    "                # compute P(O|hmm)\n",
    "                denom = sum(alpha[:,-1])\n",
    "                for i in range(n_states):\n",
    "                    # numer[1,:] = row vector, alpha[i,t] = real number, self.A[i,:] = column vector\n",
    "                    # self.B[:,observations[t+1].T] = row vector, beta[:,t+1].T = column vector\n",
    "                    numer = alpha[i,t] * self.B[:,observations[t+1]].T * beta[:,t+1].T\n",
    "                    xi[i,:,t] = numer/denom\n",
    "                    \n",
    "            # compute gamma_t(i) sum the j values\n",
    "            gamma = np.sum(xi,axis = 1)\n",
    "            # need final gamma elements for new B\n",
    "            prod = (alpha[:,n_samples - 1] * beta[:,n_samples-1]).reshape((-1,1))\n",
    "            # sum the nodes that all from T time\n",
    "            gamma = np.hstack((gamma, prod / np.sum(prod)))\n",
    "            #colum vector\n",
    "            newpi = gamma[:,0]\n",
    "            newA = np.sum(xi,2) / np.sum(gamma[:,:-1], axis = 1).reshape((-1,1))\n",
    "            newB = np.copy(self.B) \n",
    "\n",
    "            # the observation state number\n",
    "            num_levels = self.B.shape[1]\n",
    "            summgamma = np.sum(gamma, axis = 1)\n",
    "            for lev in range(num_levels):\n",
    "                mask = observations == lev\n",
    "                newB[:,lev] = np.sum(gamma[:,mask],axis =1) / summgamma\n",
    "\n",
    "            if np.max(abs(self.pi - newpi)) < criterion and \\\n",
    "               np.max(abs(self.A - newA)) < criterion and \\\n",
    "               np.max(abs(self.B - newB)) < criterion:\n",
    "                done = 1\n",
    "\n",
    "            self.A[:],self.B[:],self.pi[:] = newA,newB,newpi\n",
    "\n",
    "    #模拟序列生成函数\n",
    "    def simulate(self,T):\n",
    "        def draw_from(probs):\n",
    "            #np.random.multinomial 为多项式分布，1为试验次数，probs是每个点数的概率，均为1/6\n",
    "            #给定行向量的概率，投掷次数为1次，寻找投掷的点数\n",
    "            return np.where(np.random.multinomial(1,probs)==1)[0][0]\n",
    "        \n",
    "        observations = np.zeros(T,dtype = int)\n",
    "        states = np.zeros(T,dtype = int)\n",
    "        states[0] = draw_from(self.pi)\n",
    "        observations[0] = draw_from(self.B[states[0],:])\n",
    "        for t in range(1,T):\n",
    "            states[t] = draw_from(self.A[states[t-1],:])\n",
    "            observations[t] = draw_from(self.B[states[t],:])\n",
    "        return observations,states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3974140",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HMM_spike:\n",
    "    def __init__(self,mu,P,cov):\n",
    "        self.P = P #spike shoting rate 神经元发放速率\n",
    "        self.mu = mu\n",
    "        self.cov = cov\n",
    "        \n",
    "    # 计算 probability matrix A 状态转移概率矩阵 K * K\n",
    "    def proba_matrix(self,k):\n",
    "        tran_pro = np.append(np.zeros([1,k]),np.append(np.eye(k-1,dtype=float),np.zeros([k-1,1]),axis=1),axis=0)\n",
    "        tran_pro[0,0],tran_pro[1,0],tran_pro[0,-1] = 1-self.P,self.P,1\n",
    "        \n",
    "        return tran_pro\n",
    "    \n",
    "    #计算 state-conditional sample probability B 观察概率 K * T\n",
    "    def state_conditional(self,obs_seq,K):\n",
    "        T = obs_seq.shape[0]\n",
    "        U = self.mu * np.ones((1,T))\n",
    "        st_con_mat = np.exp(-1 * np.\n",
    "                            square(np.ones((K,1)) * obs_seq - U ) / (2 * np.square(self.cov))) / ((2 * np.pi) ** 0.5 * self.cov)\n",
    "\n",
    "        return st_con_mat\n",
    "        \n",
    "    #向前算法（F为/alpha_t(i)）\n",
    "    def _forward(self,K,T):\n",
    "        #取A = N x N\n",
    "        F = np.mat(np.zeros((K,T)))\n",
    "        \n",
    "        #alpha = pi*b\n",
    "        F[:,0] = 1\n",
    "        for t in range(1,T):\n",
    "            F[:,t] = np.multiply(self.B[:,t],self.A.T * F[:,t-1])\n",
    "            #rescaled\n",
    "            F[:,t] = F[:,t] / np.linalg.norm(F[:,t],ord=1)\n",
    "        \n",
    "        return F    \n",
    "\n",
    "    #向后算法\n",
    "    def _backward(self,K,T):\n",
    "        X = np.mat(np.zeros((K,T)))\n",
    "        #表示X矩阵的最后一列\n",
    "        X[:,-1:] = 1\n",
    "        \n",
    "        for t in reversed(range(T-1)):\n",
    "            # 边权值为a_ji\n",
    "            X[:,t] = self.A * np.multiply(self.B[:,t+1], X[:,t+1])\n",
    "            #rescaled\n",
    "            X[:,t] = X[:,t] / np.linalg.norm(X[:,t],ord=1)\n",
    "        return X\n",
    "    \n",
    "    #维特比算法\n",
    "    def viterbi(self,obs_seq):\n",
    "        \n",
    "        N = self.A.shape[0]\n",
    "        T = len(obs_seq)\n",
    "        \n",
    "        prev = np.zeros((T-1,N),dtype = int)\n",
    "        \n",
    "        V = np.zeros((N,T))\n",
    "        V[0,0] = 1\n",
    "        \n",
    "        for t in range(1,T):\n",
    "            for n in range(N):\n",
    "                #计算delta(j)*a_ji\n",
    "                seq_probs = V[:,t-1]*self.A[:,n]*self.B[n,t]\n",
    "                #计算最大状态转移过程\n",
    "                prev[t-1,n] = np.argmax(seq_probs)\n",
    "                V[n,t] = max(seq_probs) \n",
    "        return V,prev\n",
    "    \n",
    "    def build_viterbi_path(self,prev,last_state):\n",
    "        \"\"\"\n",
    "        returns a state path ending in last_state in reverse order\n",
    "        \"\"\"\n",
    "        T = len(prev)\n",
    "        yield(last_state)\n",
    "\n",
    "        #从T-1开始，每次下降1\n",
    "        for i in range(T-1,-1,-1):\n",
    "            yield(prev[i,last_state])\n",
    "            last_state = prev[i,last_state]\n",
    "\n",
    "    def stat_path(self,obs_seq):\n",
    "        V,prev = self.viterbi(obs_seq)\n",
    "        \n",
    "        #build state path with greatest probability\n",
    "        last_state = np.argmax(V[:,-1]) \n",
    "        path = list(self.build_viterbi_path(prev,last_state))\n",
    "        \n",
    "        return V[last_state,-1],reversed(path)\n",
    "    \n",
    "    #Baum-Welch算法 for spike shooting\n",
    "    def baum_welch_train(self,observations,criterion=0.05):\n",
    "        n_states = self.mu.shape[0]\n",
    "        #观察序列长度T\n",
    "        n_samples = len(observations)\n",
    "        \n",
    "        self.A = self.proba_matrix(n_states)\n",
    "        self.B = self.state_conditional(observations,n_states) \n",
    "        lock = 0\n",
    "        while (lock < 8):\n",
    "            #alpha_t(i) = P(o_1,o_2,...o_t,q_t = s_i | hmm)\n",
    "            #Initialize alpha\n",
    "            #获得所有向前传播节点值alpha_t(i)\n",
    "            alpha = self._forward(n_states,n_samples)\n",
    "            \n",
    "            # beta_t(i) = P(o_t+1,o_t+2,...o_T | q_t = s_i, hmm) \n",
    "            # Initialize beta\n",
    "            # 获得所有后向传播节点值\n",
    "            beta = self._backward(n_states,n_samples)\n",
    "            \n",
    "            #gamma = np.multiply(alpha,beta)\n",
    "            gamma = np.multiply(self.A.T * alpha,np.multiply(self.B ,beta))\n",
    "            newmu = np.zeros((1,n_states))\n",
    "             # in each moment\n",
    "            for t in range(n_samples):\n",
    "                gamma[:,t] = gamma[:,t] / np.linalg.norm(gamma[:,t], ord=1)\n",
    "                newmu = np.dot(np.dot(observations[t], gamma[:,t].T).reshape(1,-1),np.linalg.pinv(np.dot(gamma[:,t].reshape(-1,1),gamma[:,t].reshape(1,-1))))\n",
    "            #print(gamma)\n",
    "        \n",
    "            \n",
    "            newcov = np.mean(np.multiply(observations,observations)) - np.mean(np.multiply(np.dot(newmu,gamma),observations))\n",
    "            newP = np.sum(gamma[1,1:])/np.sum(gamma[0,:-1])\n",
    "            \n",
    "            if newP * 240000 < 0.5:\n",
    "                break\n",
    "            \n",
    "            self.mu,self.cov,self.P = newmu.reshape(-1,1),newcov,newP\n",
    "          #  print(newmu)\n",
    "            \n",
    "            self.A = self.proba_matrix(n_states)\n",
    "            self.B = self.state_conditional(observations,n_states) \n",
    "            lock += 1\n",
    "           \n",
    "           \n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2829f9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HMM_multi_spike:\n",
    "    def __init__(self,mu,P,cov):\n",
    "        self.P = P #spike shoting rate 神经元发放速率\n",
    "        self.mu = np.mat(mu)\n",
    "        self.cov = cov\n",
    "    \n",
    "    # 计算简化过的隐藏层层数\n",
    "    def hidden_state(self,N,R,K):\n",
    "    #allow no more than R (for example R = 2) neurons to simultaneously spike: K^N reduce to 1 + N(K-1) + N(N-1)(K-1)^2 / 2 \n",
    "        if R > 3:\n",
    "            R = 3\n",
    "            print(\"no more than 3 simultaneously sipke neurons allowed\")\n",
    "        hk = 1\n",
    "        HK = 1\n",
    "        for i in range(1,R+1):\n",
    "            hk = hk * (N - i+1) * ( K - 1 )\n",
    "            HK += hk / i\n",
    "        return int(HK)\n",
    "    \n",
    "    # 计算 probability matrix A 状态转移概率矩阵 K * K\n",
    "    def proba_matrix(self,TotalK,K,N):\n",
    "        #正常用np.kron\n",
    "        tran_pro = np.append(np.zeros([1,TotalK]),np.append(np.eye(TotalK-1,dtype=float),np.zeros([TotalK-1,1]),axis=1),axis=0)\n",
    "        for n in range(N):\n",
    "            tran_pro[0,n*(K-1)],tran_pro[n*(K-1)+1,n*(K-1)]= 1,0\n",
    "            tran_pro[n*(K-1)+1,0] = self.P[n]\n",
    "        tran_pro[0,0],tran_pro[0,-1]= 1-sum(self.P),1\n",
    "        return tran_pro\n",
    "    \n",
    "    #计算 state-conditional sample probability B 观察概率 K * T\n",
    "    def state_conditional(self,TotalK,obs_seq,K,N):\n",
    "        multi_mu_sum = np.mat(np.zeros((TotalK,obs_seq.shape[0])))\n",
    "        multi_mu_sum[0,:] = norm.pdf(obs_seq,sum(self.mu[:,0]),self.cov**0.5)\n",
    "        for n in range(N):\n",
    "            for k in range(K-1):\n",
    "                multi_mu_sum[1 + n*(K-1) + k,:] = norm.pdf(obs_seq,self.mu[k+1,n],self.cov**0.5)\n",
    "        return multi_mu_sum\n",
    "        \n",
    "    #向前算法（F为/alpha_t(i)）\n",
    "    def _forward(self,K,T):\n",
    "        #取A = N x N\n",
    "        \n",
    "        F = np.mat(np.zeros((K,T)))\n",
    "        \n",
    "        #alpha = pi*b\n",
    "        F[:,0] = 1\n",
    "        for t in range(1,T):\n",
    "            F[:,t] = np.multiply( self.B[:,t], np.sum(np.multiply(F[:,t-1],np.mat(self.A)),axis=1))\n",
    "            #rescaled\n",
    "            F[:,t] = F[:,t] / np.linalg.norm(F[:,t],ord=1)\n",
    "\n",
    "        return F    \n",
    "\n",
    "    #向后算法\n",
    "    def _backward(self,K,T):\n",
    "        \n",
    "        X = np.mat(np.zeros((K,T)))\n",
    "        #表示X矩阵的最后一列\n",
    "        X[:,-1:] = 1\n",
    "        \n",
    "        for t in reversed(range(T-1)):\n",
    "            # 边权值为a_ji\n",
    "            # X[:,t] =  np.multiply( X[:,t+1], np.sum(np.multiply(self.B[:,t+1],np.mat(self.A).T),axis=0).T )\n",
    "            X[:,t] =  np.sum(np.multiply( np.mat(self.A).T, np.multiply(self.B[:,t+1],X[:,t+1]) ),axis=0).T\n",
    "            #rescaled\n",
    "            X[:,t] = X[:,t] / np.linalg.norm(X[:,t],ord=1)\n",
    "        return X\n",
    "    \n",
    "    #维特比算法\n",
    "    def viterbi(self,obs_seq):\n",
    "        \n",
    "        N = self.A.shape[0]\n",
    "        T = len(obs_seq)\n",
    "        \n",
    "        prev = np.zeros((T-1,N),dtype = int)\n",
    "        \n",
    "        V = np.zeros((N,T))\n",
    "        V[0,0] = 1\n",
    "        \n",
    "        for t in range(1,T):\n",
    "            for n in range(N):\n",
    "                #计算delta(j)*a_ji\n",
    "                seq_probs = V[:,t-1]*self.A[:,n]*self.B[n,t]\n",
    "                #计算最大状态转移过程\n",
    "                prev[t-1,n] = np.argmax(seq_probs)\n",
    "                V[n,t] = max(seq_probs)\n",
    "                \n",
    "        return V,prev\n",
    "    \n",
    "    def build_viterbi_path(self,prev,last_state):\n",
    "        \"\"\"\n",
    "        returns a state path ending in last_state in reverse order\n",
    "        \"\"\"\n",
    "        T = len(prev)\n",
    "        yield(last_state)\n",
    "\n",
    "        #从T-1开始，每次下降1\n",
    "        for i in range(T-1,-1,-1):\n",
    "            yield(prev[i,last_state])\n",
    "            last_state = prev[i,last_state]\n",
    "\n",
    "    def stat_path(self,obs_seq):\n",
    "        V,prev = self.viterbi(obs_seq)\n",
    "        \n",
    "        #build state path with greatest probability\n",
    "        last_state = np.argmax(V[:,-1]) \n",
    "        path = list(self.build_viterbi_path(prev,last_state))\n",
    "        \n",
    "        return V[last_state,-1],reversed(path)\n",
    "    \n",
    "    #Baum-Welch算法 for spike shooting\n",
    "    def baum_welch_train(self,observations,mspike = 1,maxterion=2):\n",
    "        n_states = self.mu.shape[0] \n",
    "        n_neuron = self.mu.shape[1]\n",
    "        #观察序列长度T\n",
    "        n_samples = len(observations)\n",
    "       \n",
    "        n_totlK = self.hidden_state(n_neuron,mspike,n_states)\n",
    "        state_name = list(range(0,n_states))\n",
    "        #combin = list(itertools.product(state_name,repeat=n_neuron))\n",
    "\n",
    "        self.A = self.proba_matrix(n_totlK,n_states,n_neuron)\n",
    "        self.B = self.state_conditional(n_totlK,observations,n_states,n_neuron) \n",
    "        lock = 0\n",
    "        while (lock < maxterion):\n",
    "            #alpha_t(i) = P(o_1,o_2,...o_t,q_t = s_i | hmm)\n",
    "            #Initialize alpha\n",
    "            #获得所有向前传播节点值alpha_t(i)\n",
    "            alpha = self._forward(n_totlK,n_samples)\n",
    "            self.alpha = alpha\n",
    "            # beta_t(i) = P(o_t+1,o_t+2,...o_T | q_t = s_i, hmm) \n",
    "            # Initialize beta\n",
    "            # 获得所有后向传播节点值\n",
    "            beta = self._backward(n_totlK,n_samples)\n",
    "            self.beta = beta\n",
    "            \n",
    "            self.gamma = np.multiply(alpha,beta)  \n",
    "            self.gamma = self.gamma / (np.linalg.norm(self.gamma,ord=1,axis=0))\n",
    "                             \n",
    "            self.titaa = np.zeros((n_neuron,n_states,n_samples))\n",
    "            for n in range(n_neuron):\n",
    "                self.titaa[n,0,:],self.titaa[n,1:,:] = self.gamma[0,:],self.gamma[n*(n_states-1) + 1:(n+1)*(n_states-1)+1,:]\n",
    "            \n",
    "            #update the P\n",
    "            newP = np.zeros(n_neuron)\n",
    "            for n in range(n_neuron):\n",
    "                newP[n] = np.sum(self.titaa[n,1,1:])/np.sum(self.titaa[n,0,:-2])\n",
    "            #if some ith probability p^i corresponded to f firing rate of 0.5hz or less\n",
    "            newP = [0.99 * np.random.choice([x for x in newP if x > p])if ( p * 24000 <= 0.5 and p != max(newP) )else p for p in newP]\n",
    "            #if signal-tp-onise variance of recording is very low --- noise covariance self.cov is very high\n",
    "            #if newcov < 1:\n",
    "            #    self.P = [10**(-10) for p in self.P]\n",
    "            \n",
    "            \n",
    "            #update the mu\n",
    "            siggma = np.mat(self.titaa.reshape((n_neuron * n_states ,n_samples)))\n",
    "            newmu = np.dot(np.sum(np.multiply(observations,siggma),axis = 1).T,np.linalg.pinv(siggma * siggma.T))\n",
    "            multi_mu = np.mat(newmu.reshape((n_neuron,-1)))\n",
    "            \n",
    "            #update the cov\n",
    "            mu_sum = np.zeros((1,n_samples))\n",
    "            for n in range(n_neuron):\n",
    "                    mu_sum[0,:] = mu_sum[0,:] + multi_mu[n,:] * np.mat(self.titaa[n,:,:])\n",
    "            newcov = np.mean(np.multiply(observations,observations)) - np.mean(np.multiply(mu_sum,observations))\n",
    "            #print(np.max(abs(self.mu - newmu)),  np.max(abs(self.P - newP)), np.max(abs(self.cov - newcov))) \n",
    "            \n",
    "            self.mu, self.cov, self.P = multi_mu.T, newcov, newP\n",
    "            print(self.P)\n",
    "            self.A = self.proba_matrix(n_totlK,n_states,n_neuron)\n",
    "            self.B = self.state_conditional(n_totlK,observations,n_states,n_neuron) \n",
    "            lock += 1\n",
    "           \n",
    "           \n",
    "        return \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
